"""
LP Intelligence System - Unified Runner with History
Version: 2.0.0

ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµÑ‚:
1. LP Monitor - Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹
2. LP Opportunities - Ğ¿Ğ¾Ğ¸ÑĞº Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ğ¿ÑƒĞ»Ğ¾Ğ²  
3. LP Advisor - AI Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸
4. History - Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° TVL

Ğ Ğ°ÑĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ: 7:00 Ğ¸ 19:00 MSK (04:00 Ğ¸ 16:00 UTC)
"""

import json
import logging
import os
import sys
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict

import requests

# Logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONSTANTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

HISTORY_FILE = "state/lp_history.json"
MAX_HISTORY_DAYS = 90  # Keep 90 days of history

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HISTORY MANAGEMENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class DailySnapshot:
    """Daily portfolio snapshot"""
    date: str  # YYYY-MM-DD
    timestamp: str  # ISO format
    tvl: float
    fees: float  # Current uncollected fees
    fees_cumulative: float  # All fees earned ever (doesn't reset on harvest)
    positions_count: int
    positions_in_range: int
    by_wallet: Dict[str, float]  # wallet_name -> tvl
    by_wallet_fees: Dict[str, float]  # wallet_name -> fees


def load_history() -> List[dict]:
    """Load history from file"""
    if not os.path.exists(HISTORY_FILE):
        return []
    
    try:
        with open(HISTORY_FILE, 'r') as f:
            data = json.load(f)
            return data.get("snapshots", [])
    except Exception as e:
        logger.warning(f"Error loading history: {e}")
        return []


def save_history(snapshots: List[dict]):
    """Save history to file"""
    os.makedirs(os.path.dirname(HISTORY_FILE), exist_ok=True)
    
    # Keep only last MAX_HISTORY_DAYS
    cutoff_date = (datetime.now(timezone.utc) - timedelta(days=MAX_HISTORY_DAYS)).strftime("%Y-%m-%d")
    snapshots = [s for s in snapshots if s.get("date", "") >= cutoff_date]
    
    with open(HISTORY_FILE, 'w') as f:
        json.dump({"snapshots": snapshots, "updated": datetime.now(timezone.utc).isoformat()}, f, indent=2)
    
    logger.info(f"History saved: {len(snapshots)} snapshots")


def add_snapshot(tvl: float, fees: float, positions_count: int, in_range: int, 
                 by_wallet: Dict[str, float], by_wallet_fees: Dict[str, float]):
    """Add today's snapshot to history with cumulative fees tracking"""
    snapshots = load_history()
    
    today = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    now = datetime.now(timezone.utc).isoformat()
    
    # Calculate cumulative fees
    # Logic: if current fees < previous fees, user did harvest
    # We add the positive delta to cumulative, never subtract
    fees_cumulative = fees  # default for first snapshot
    
    if snapshots:
        # Find the most recent snapshot (any date)
        prev_snapshot = snapshots[-1]
        prev_fees = prev_snapshot.get("fees", 0)
        prev_cumulative = prev_snapshot.get("fees_cumulative", prev_fees)
        
        if fees >= prev_fees:
            # Fees grew normally - add the delta
            fees_cumulative = prev_cumulative + (fees - prev_fees)
        else:
            # Fees dropped = harvest happened
            # The user collected prev_fees, now accumulating new fees
            # cumulative = prev_cumulative + (what was harvested is already in cumulative via prev deltas)
            # We just add current fees as new accumulation since harvest
            fees_cumulative = prev_cumulative + fees
            logger.info(f"Detected harvest: fees dropped from ${prev_fees:.2f} to ${fees:.2f}")
    
    # Check if today's snapshot exists
    existing_idx = None
    for i, s in enumerate(snapshots):
        if s.get("date") == today:
            existing_idx = i
            # Keep the higher cumulative (in case of multiple runs per day)
            prev_today_cumulative = s.get("fees_cumulative", 0)
            fees_cumulative = max(fees_cumulative, prev_today_cumulative)
            break
    
    snapshot = {
        "date": today,
        "timestamp": now,
        "tvl": tvl,
        "fees": fees,
        "fees_cumulative": fees_cumulative,
        "positions_count": positions_count,
        "positions_in_range": in_range,
        "by_wallet": by_wallet,
        "by_wallet_fees": by_wallet_fees,
    }
    
    if existing_idx is not None:
        # Update existing
        snapshots[existing_idx] = snapshot
    else:
        # Add new
        snapshots.append(snapshot)
    
    # Sort by date
    snapshots.sort(key=lambda x: x.get("date", ""))
    
    save_history(snapshots)
    
    logger.info(f"Snapshot saved: TVL=${tvl:.0f}, fees=${fees:.2f}, cumulative=${fees_cumulative:.2f}")
    return snapshot


def get_tvl_change(snapshots: List[dict], current_tvl: float, days: int) -> Tuple[Optional[float], Optional[float]]:
    """Get TVL change over N days. Returns (absolute_change, percent_change)"""
    if len(snapshots) < 2:
        return None, None
    
    target_date = (datetime.now(timezone.utc) - timedelta(days=days)).strftime("%Y-%m-%d")
    
    # Find closest snapshot to target date
    past_snapshot = None
    for s in snapshots:
        if s.get("date", "") <= target_date:
            past_snapshot = s
    
    if not past_snapshot:
        return None, None
    
    past_tvl = past_snapshot.get("tvl", 0)
    if past_tvl == 0:
        return None, None
    
    abs_change = current_tvl - past_tvl
    pct_change = (abs_change / past_tvl) * 100
    
    return abs_change, pct_change


def calculate_portfolio_apy(snapshots: List[dict], current_tvl: float) -> Optional[float]:
    """Calculate portfolio APY based on cumulative fees earned"""
    if len(snapshots) < 2:
        return None
    
    # Get current snapshot (last one)
    current = snapshots[-1]
    current_cumulative = current.get("fees_cumulative", 0)
    
    # Try to find snapshot from ~7 days ago, then 3 days, then 1 day
    for days in [7, 3, 1]:
        target_date = (datetime.now(timezone.utc) - timedelta(days=days)).strftime("%Y-%m-%d")
        
        past_snapshot = None
        for s in snapshots:
            if s.get("date", "") <= target_date:
                past_snapshot = s
        
        if past_snapshot and past_snapshot.get("date") != current.get("date"):
            past_cumulative = past_snapshot.get("fees_cumulative", 0)
            past_tvl = past_snapshot.get("tvl", 0)
            
            # Calculate fees earned in this period
            fees_earned = current_cumulative - past_cumulative
            
            if fees_earned > 0 and past_tvl > 0:
                # Average TVL over period
                avg_tvl = (current_tvl + past_tvl) / 2
                
                # Calculate actual days between snapshots
                from datetime import datetime as dt
                current_date = dt.strptime(current.get("date"), "%Y-%m-%d")
                past_date = dt.strptime(past_snapshot.get("date"), "%Y-%m-%d")
                actual_days = (current_date - past_date).days
                
                if actual_days > 0:
                    # Annualize
                    apy = (fees_earned / avg_tvl) * (365 / actual_days) * 100
                    logger.info(f"APY calc: ${fees_earned:.2f} earned over {actual_days}d, avg TVL ${avg_tvl:.0f} = {apy:.1f}%")
                    return apy
    
    return None


def format_change(abs_change: Optional[float], pct_change: Optional[float]) -> str:
    """Format change for display"""
    if abs_change is None or pct_change is None:
        return "Ğ½ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"
    
    # Don't show +$0 changes (means no historical data)
    if abs_change == 0 and pct_change == 0:
        return "Ğ½ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"
    
    sign = "+" if abs_change >= 0 else ""
    return f"{sign}${abs_change:,.0f} ({sign}{pct_change:.1f}%)"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# UNIFIED RUNNER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_monitor() -> Optional[dict]:
    """Run LP Monitor and return summary"""
    try:
        from lp_monitor import LPMonitor
        
        monitor = LPMonitor()
        
        if not monitor.web3_clients:
            logger.warning("No chains connected")
            return None
        
        positions = monitor.scan_all_positions()
        
        if not positions:
            logger.warning("No positions found")
            return None
        
        summary = monitor.get_summary()
        monitor.save_state()
        
        return {
            "positions": [asdict(p) for p in monitor.positions],
            "summary": asdict(summary),
            "tvl": summary.total_balance_usd,
            "fees": summary.total_uncollected_fees_usd,
            "count": summary.total_positions,
            "in_range": summary.positions_in_range,
            "by_wallet": summary.by_wallet,
        }
        
    except Exception as e:
        logger.error(f"Monitor error: {e}")
        return None


def run_opportunities() -> Optional[dict]:
    """Run LP Opportunities Scanner and return top pools"""
    try:
        from lp_opportunities import LPOpportunitiesScanner
        from lp_config import REGIME_IL_PENALTY
        
        scanner = LPOpportunitiesScanner()
        opportunities = scanner.scan()
        
        if not opportunities:
            logger.warning("No opportunities found")
            return None
        
        scanner.save_state()
        rankings = scanner.get_rankings()
        
        # LP recommendation based on regime (Russian)
        regime = scanner.regime
        regime_penalty = REGIME_IL_PENALTY.get(regime, 0.4)
        
        lp_recommendations_ru = {
            "HARVEST": "Ğ˜Ğ´ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ Ğ´Ğ»Ñ LP. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ ÑƒĞ·ĞºĞ¸Ğµ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ñ‹.",
            "RANGE": "Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¸Ğµ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ. Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ñ‹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚.",
            "MEAN_REVERT": "Ğ£Ğ¼ĞµÑ€ĞµĞ½Ğ½Ñ‹Ğµ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ. Ğ¡Ğ»ĞµĞ´Ğ¸Ñ‚Ğµ Ğ·Ğ° Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ°Ğ¼Ğ¸.",
            "VOLATILE_CHOP": "Ğ’Ğ¾Ğ»Ğ°Ñ‚Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ ÑˆĞ¸Ñ€Ğ¾ĞºĞ¸Ğµ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ñ‹.",
            "TRANSITION": "ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´. ĞÑÑ‚Ğ¾Ñ€Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ.",
            "BULL": "Ğ¢Ñ€ĞµĞ½Ğ´ Ğ²Ğ²ĞµÑ€Ñ…. Ğ Ğ¸ÑĞº IL Ğ½Ğ° short Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸ÑÑ….",
            "BEAR": "Ğ¢Ñ€ĞµĞ½Ğ´ Ğ²Ğ½Ğ¸Ğ·. Ğ’Ñ‹ÑĞ¾ĞºĞ¸Ğ¹ Ñ€Ğ¸ÑĞº IL. ĞŸÑ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ğ¹Ñ‚Ğµ stable Ğ¿Ğ°Ñ€Ñ‹.",
            "TRENDING": "Ğ¡Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ñ€ĞµĞ½Ğ´. ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ LP ÑĞºÑĞ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ.",
            "BREAKOUT": "ĞŸÑ€Ğ¾Ğ±Ğ¾Ğ¹. Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶ĞµĞ½ ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ IL.",
            "CHURN": "Ğ¥Ğ°Ğ¾Ñ. Ğ›ÑƒÑ‡ÑˆĞµ Ğ²Ñ‹Ğ¹Ñ‚Ğ¸ Ğ¸Ğ· Ñ€Ğ¸ÑĞºĞ¾Ğ²Ñ‹Ñ… Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹.",
            "AVOID": "Ğ˜Ğ·Ğ±ĞµĞ³Ğ°Ğ¹Ñ‚Ğµ LP. Ğ’Ñ‹ÑĞ¾ĞºĞ¸Ğ¹ Ñ€Ğ¸ÑĞº.",
        }
        
        return {
            "regime": regime,
            "regime_penalty": regime_penalty,
            "lp_recommendation": lp_recommendations_ru.get(regime, "ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼."),
            "top_pools": [
                {
                    "symbol": o.symbol,
                    "chain": o.chain,
                    "apy": o.apy_total,
                    "risk_adj_apy": o.risk_adjusted_apy,
                    "tvl": o.tvl_usd,
                    "il_risk": o.il_risk_label,
                }
                for o in rankings["by_risk_adjusted"][:10]  # Top 10
            ]
        }
        
    except Exception as e:
        logger.error(f"Opportunities error: {e}")
        return None


def run_advisor(monitor_data: dict, opportunities_data: Optional[dict], history: List[dict]) -> Optional[str]:
    """Run LP Advisor with proper APY and regime analysis"""
    
    # Check for OpenAI key first
    openai_key = os.getenv("OPENAI_API_KEY")
    if not openai_key:
        logger.warning("OPENAI_API_KEY not set - skipping AI summary")
        return None
    
    try:
        # === BUILD ANALYSIS CONTEXT ===
        
        tvl = monitor_data.get("tvl", 0)
        fees = monitor_data.get("fees", 0)
        positions = monitor_data.get("positions", [])
        
        # Regime info
        regime = opportunities_data.get("regime", "UNKNOWN") if opportunities_data else "UNKNOWN"
        regime_penalty = opportunities_data.get("regime_penalty", 0.4) if opportunities_data else 0.4
        
        # Portfolio APY (calculated from history)
        portfolio_apy = opportunities_data.get("portfolio_apy") if opportunities_data else None
        
        # Benchmark - average of top 5 pools
        benchmark_apy = None
        top_pools = []
        if opportunities_data and opportunities_data.get("top_pools"):
            top_pools = opportunities_data["top_pools"][:5]
            if top_pools:
                benchmark_apy = sum(p.get("risk_adj_apy", 0) for p in top_pools) / len(top_pools)
        
        # === ANALYZE EACH POSITION FOR REGIME FIT ===
        
        # Token type classification
        def get_token_type(symbol: str) -> str:
            s = symbol.upper()
            stables = {"USDC", "USDT", "DAI", "BUSD", "FRAX", "FDUSD"}
            majors = {"WETH", "ETH", "WBTC", "BTC", "BTCB", "WBNB", "BNB"}
            if s in stables:
                return "stable"
            if s in majors:
                return "major"
            return "alt"
        
        # Regime suitability
        def get_regime_fit(t0_type: str, t1_type: str, regime: str) -> str:
            """Evaluate if pair fits current regime"""
            pair_type = f"{t0_type}/{t1_type}"
            
            # Stable/stable - always good
            if t0_type == "stable" and t1_type == "stable":
                return "Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾"
            
            # Stable/major - good in most regimes
            if (t0_type == "stable" and t1_type == "major") or (t0_type == "major" and t1_type == "stable"):
                if regime in ["BEAR", "TRENDING", "CHURN"]:
                    return "ÑƒĞ¼ĞµÑ€ĞµĞ½Ğ½Ğ¾ (Ñ€Ğ¸ÑĞº IL)"
                return "Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾"
            
            # Major/major - moderate IL risk
            if t0_type == "major" and t1_type == "major":
                if regime in ["BEAR", "TRENDING"]:
                    return "Ñ€Ğ¸ÑĞº IL Ğ¿Ñ€Ğ¸ Ñ‚Ñ€ĞµĞ½Ğ´Ğµ"
                return "Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾"
            
            # Anything with alt - high risk
            if t0_type == "alt" or t1_type == "alt":
                if regime in ["BEAR", "TRENDING", "CHURN"]:
                    return "Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¹ Ñ€Ğ¸ÑĞº IL!"
                return "ÑƒĞ¼ĞµÑ€ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ€Ğ¸ÑĞº"
            
            return "Ğ½ĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ¾"
        
        # Analyze positions
        position_analyses = []
        for p in positions:
            t0 = p.get("token0_symbol", "")
            t1 = p.get("token1_symbol", "")
            balance = p.get("balance_usd", 0)
            in_range = p.get("in_range", False)
            wallet = p.get("wallet_name", "")
            
            t0_type = get_token_type(t0)
            t1_type = get_token_type(t1)
            regime_fit = get_regime_fit(t0_type, t1_type, regime)
            
            position_analyses.append({
                "wallet": wallet,
                "pair": f"{t0}-{t1}",
                "balance": balance,
                "in_range": in_range,
                "type": f"{t0_type}/{t1_type}",
                "regime_fit": regime_fit,
            })
        
        # Group by wallet for summary
        from collections import defaultdict
        by_wallet = defaultdict(list)
        for pa in position_analyses:
            by_wallet[pa["wallet"]].append(pa)
        
        # === BUILD AI PROMPT ===
        
        # APY comparison section
        apy_section = ""
        if portfolio_apy and benchmark_apy:
            diff = portfolio_apy - benchmark_apy
            if diff > 5:
                apy_section = f"Ğ’Ğ°Ñˆ Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒ: {portfolio_apy:.1f}% APY, Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº: {benchmark_apy:.1f}%. Ğ’Ñ‹ Ğ¾Ğ±Ğ³Ğ¾Ğ½ÑĞµÑ‚Ğµ Ñ€Ñ‹Ğ½Ğ¾Ğº Ğ½Ğ° {diff:.1f}%!"
            elif diff > -5:
                apy_section = f"Ğ’Ğ°Ñˆ Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒ: {portfolio_apy:.1f}% APY, Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº: {benchmark_apy:.1f}%. ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ğµ Ñ€Ñ‹Ğ½ĞºĞ°."
            else:
                apy_section = f"Ğ’Ğ°Ñˆ Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒ: {portfolio_apy:.1f}% APY, Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº: {benchmark_apy:.1f}%. ĞÑ‚ÑÑ‚Ğ°Ñ‘Ñ‚Ğµ Ğ½Ğ° {abs(diff):.1f}%."
        elif portfolio_apy:
            apy_section = f"Ğ’Ğ°Ñˆ Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒ: {portfolio_apy:.1f}% APY (Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ¾Ğ¼)."
        else:
            apy_section = "APY Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»Ñ: Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 2 Ğ´Ğ½Ñ)."
        
        # Regime section
        regime_descriptions = {
            "BULL": "Ğ±Ñ‹Ñ‡Ğ¸Ğ¹ Ñ‚Ñ€ĞµĞ½Ğ´ - Ñ€Ñ‹Ğ½Ğ¾Ğº Ñ€Ğ°ÑÑ‚Ñ‘Ñ‚",
            "BEAR": "Ğ¼ĞµĞ´Ğ²ĞµĞ¶Ğ¸Ğ¹ Ñ‚Ñ€ĞµĞ½Ğ´ - Ñ€Ñ‹Ğ½Ğ¾Ğº Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚",
            "RANGE": "Ğ±Ğ¾ĞºĞ¾Ğ²Ğ¸Ğº - Ñ€Ñ‹Ğ½Ğ¾Ğº ĞºĞ¾Ğ½ÑĞ¾Ğ»Ğ¸Ğ´Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ",
            "TRENDING": "ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ñ€ĞµĞ½Ğ´",
            "VOLATILE_CHOP": "Ğ²Ñ‹ÑĞ¾ĞºĞ°Ñ Ğ²Ğ¾Ğ»Ğ°Ñ‚Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ±ĞµĞ· Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ",
            "TRANSITION": "Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´, Ğ½ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ",
            "HARVEST": "Ğ¸Ğ´ĞµĞ°Ğ»ÑŒĞ½Ğ¾ Ğ´Ğ»Ñ LP",
            "CHURN": "Ñ…Ğ°Ğ¾Ñ‚Ğ¸Ñ‡Ğ½Ğ¾Ğµ Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ",
        }
        regime_desc = regime_descriptions.get(regime, regime)
        
        # Position details by wallet
        wallet_details = []
        for wallet_name in sorted(by_wallet.keys()):
            positions_info = []
            for pa in by_wallet[wallet_name]:
                status = "âœ“" if pa["in_range"] else "âœ—"
                positions_info.append(f"{pa['pair']} (${pa['balance']:.0f}, {pa['type']}, {pa['regime_fit']})")
            wallet_details.append(f"{wallet_name}: {'; '.join(positions_info)}")
        
        prompt = f"""Ğ¢Ñ‹ LP-Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ğº. ĞÑ†ĞµĞ½Ğ¸ Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒ Uniswap V3 LP Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹.

=== Ğ”ĞĞ¥ĞĞ”ĞĞĞ¡Ğ¢Ğ¬ ===
{apy_section}

Ğ¢Ğ¾Ğ¿ Ğ¿ÑƒĞ»Ñ‹ Ğ½Ğ° Ñ€Ñ‹Ğ½ĞºĞµ Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ:
{chr(10).join([f"- {p['symbol']}: {p['risk_adj_apy']:.1f}% APY" for p in top_pools[:3]]) if top_pools else "ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"}

=== Ğ¤ĞĞ—Ğ Ğ Ğ«ĞĞšĞ ===
Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼: {regime} ({regime_desc})
Ğ¨Ñ‚Ñ€Ğ°Ñ„ IL: {regime_penalty:.0%}

Ğ§Ñ‚Ğ¾ ÑÑ‚Ğ¾ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ Ğ´Ğ»Ñ LP:
- BEAR/TRENDING: Ğ°ĞºÑ‚Ğ¸Ğ²Ñ‹ Ğ¿Ğ°Ğ´Ğ°ÑÑ‚/Ñ€Ğ°ÑÑ‚ÑƒÑ‚ ÑĞ¸Ğ»ÑŒĞ½Ğ¾ â†’ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¹ Impermanent Loss
- RANGE/HARVEST: Ğ±Ğ¾ĞºĞ¾Ğ²Ğ¸Ğº â†’ Ğ¸Ğ´ĞµĞ°Ğ»ÑŒĞ½Ğ¾ Ğ´Ğ»Ñ LP, IL Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ĞµĞ½
- ĞŸÑ€Ğ¸ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¼ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ {regime} Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ: {'stable Ğ¿Ğ°Ñ€Ñ‹ Ğ¸Ğ»Ğ¸ ÑˆĞ¸Ñ€Ğ¾ĞºĞ¸Ğµ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ñ‹' if regime in ['BEAR', 'TRENDING', 'CHURN'] else 'Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸'}

=== ĞŸĞĞ—Ğ˜Ğ¦Ğ˜Ğ˜ ĞŸĞ ĞšĞĞ¨Ğ•Ğ›Ğ¬ĞšĞĞœ ===
{chr(10).join(wallet_details)}

=== Ğ—ĞĞ”ĞĞĞ˜Ğ• ===
Ğ”Ğ°Ğ¹ ĞºÑ€Ğ°Ñ‚ĞºÑƒÑ Ğ¾Ñ†ĞµĞ½ĞºÑƒ (3-4 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ):
1. Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ´Ğ¾Ñ…Ğ¾Ğ´Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»Ñ Ñ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ¾Ğ¼
2. ĞĞ°ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğµ Ğ¿Ğ°Ñ€Ñ‹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‚ Ğ¿Ğ¾Ğ´ Ñ€ĞµĞ¶Ğ¸Ğ¼ {regime}
3. ĞšĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ (ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ñ‹) Ğ¸Ğ»Ğ¸ "Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ĞµĞ½"

ĞĞ• ĞŸĞĞĞ˜ĞšĞ£Ğ™ Ğ¿Ñ€Ğ¸ Ğ¿Ñ€Ğ¾ÑĞ°Ğ´ĞºĞ°Ñ… - ÑÑ‚Ğ¾ Ñ‡Ğ°ÑÑ‚ÑŒ Ñ€Ñ‹Ğ½ĞºĞ°. Ğ¤Ğ¾ĞºÑƒÑ Ğ½Ğ° ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğµ Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»Ñ, Ğ° Ğ½Ğµ Ğ½Ğ° ĞºÑ€Ğ°Ñ‚ĞºĞ¾ÑÑ€Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸ÑÑ….
ĞÑ‚Ğ²ĞµÑ‚ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼, Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 500 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²."""

        # === CALL OPENAI ===
        
        url = "https://api.openai.com/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {openai_key}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
            "messages": [
                {
                    "role": "system",
                    "content": "Ğ¢Ñ‹ Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ DeFi LP Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ğº. Ğ”Ğ°Ñ‘ÑˆÑŒ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ±ĞµĞ· Ğ¿Ğ°Ğ½Ğ¸ĞºĞ¸. ĞŸĞ¾Ğ½Ğ¸Ğ¼Ğ°ĞµÑˆÑŒ Impermanent Loss Ğ¸ Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ğµ Ñ€Ñ‹Ğ½Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ¾Ğ² Ğ½Ğ° LP Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸."
                },
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 350,
            "temperature": 0.7
        }
        
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        
        if response.status_code == 200:
            data = response.json()
            ai_text = data["choices"][0]["message"]["content"]
            logger.info(f"AI response: {ai_text[:100]}...")
            return ai_text
        else:
            logger.error(f"OpenAI error: {response.status_code} - {response.text[:200]}")
            return None
            
    except Exception as e:
        logger.error(f"Advisor error: {e}")
        import traceback
        traceback.print_exc()
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TELEGRAM REPORT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def format_unified_report(
    monitor_data: dict,
    opportunities_data: Optional[dict],
    ai_summary: Optional[str],
    history: List[dict]
) -> str:
    """Format unified Telegram report"""
    
    now = datetime.now(timezone.utc)
    msk_time = now + timedelta(hours=3)
    
    lines = [
        "#LP #Uniswap",
        f"ğŸ“Š LP Report | {msk_time.strftime('%d.%m %H:%M')} MSK",
        "",
    ]
    
    # Summary
    tvl = monitor_data.get("tvl", 0)
    fees = monitor_data.get("fees", 0)
    count = monitor_data.get("count", 0)
    in_range = monitor_data.get("in_range", 0)
    
    lines.append(f"TVL: ${tvl:,.0f}")
    lines.append(f"Fees: ${fees:,.2f}")
    lines.append(f"In Range: {in_range}/{count}")
    
    # Portfolio APY if available
    portfolio_apy = opportunities_data.get("portfolio_apy") if opportunities_data else None
    benchmark_apy = None
    if opportunities_data and opportunities_data.get("top_pools"):
        top_5 = opportunities_data["top_pools"][:5]
        if top_5:
            benchmark_apy = sum(p.get("risk_adj_apy", 0) for p in top_5) / len(top_5)
    
    if portfolio_apy:
        apy_line = f"APY: {portfolio_apy:.1f}%"
        if benchmark_apy:
            diff = portfolio_apy - benchmark_apy
            if diff > 0:
                apy_line += f" (Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº: {benchmark_apy:.1f}%, +{diff:.1f}%)"
            else:
                apy_line += f" (Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº: {benchmark_apy:.1f}%, {diff:.1f}%)"
        lines.append(apy_line)
    
    # TVL Changes - only show if we have real data
    if len(history) >= 2:
        lines.append("")
        lines.append("Changes:")
        
        abs_1d, pct_1d = get_tvl_change(history, tvl, 1)
        abs_7d, pct_7d = get_tvl_change(history, tvl, 7)
        abs_30d, pct_30d = get_tvl_change(history, tvl, 30)
        
        lines.append(f"  24h: {format_change(abs_1d, pct_1d)}")
        lines.append(f"  7d:  {format_change(abs_7d, pct_7d)}")
        lines.append(f"  30d: {format_change(abs_30d, pct_30d)}")
    
    # Positions by wallet
    lines.append("")
    
    positions = monitor_data.get("positions", [])
    
    # Group positions by wallet
    from collections import defaultdict
    wallet_positions = defaultdict(list)
    for p in positions:
        wallet_positions[p.get("wallet_name", "")].append(p)
    
    for wallet_name in sorted(wallet_positions.keys()):
        w_positions = sorted(wallet_positions[wallet_name], key=lambda x: x.get("balance_usd", 0), reverse=True)
        w_total = sum(p.get("balance_usd", 0) for p in w_positions)
        w_fees = sum(p.get("uncollected_fees_usd", 0) for p in w_positions)
        
        lines.append(f"{wallet_name}: ${w_total:,.0f} (fees: ${w_fees:.2f})")
        
        for p in w_positions:
            # Emoji for in-range status
            status = "ğŸŸ¢" if p.get("in_range", False) else "ğŸ”´"
            symbol = f"{p.get('token0_symbol', '')}-{p.get('token1_symbol', '')}"
            balance = p.get("balance_usd", 0)
            lines.append(f"  {status} {symbol} ${balance:,.0f}")
            
            if not p.get("in_range", False):
                if p.get("current_tick", 0) < p.get("tick_lower", 0):
                    lines.append(f"    Below range {abs(p.get('distance_to_lower_pct', 0)):.1f}%")
                else:
                    lines.append(f"    Above range {abs(p.get('distance_to_upper_pct', 0)):.1f}%")
        
        lines.append("")
    
    # Top opportunities - expanded to 10, split by chain
    if opportunities_data and opportunities_data.get("top_pools"):
        arb_pools = [p for p in opportunities_data["top_pools"] if p.get("chain", "").lower() == "arbitrum"]
        bsc_pools = [p for p in opportunities_data["top_pools"] if p.get("chain", "").lower() == "bsc"]
        
        if arb_pools:
            lines.append("Top ARB:")
            for pool in arb_pools[:5]:
                lines.append(f"  {pool['symbol']}: {pool['risk_adj_apy']:.1f}%")
        
        if bsc_pools:
            lines.append("Top BSC:")
            for pool in bsc_pools[:5]:
                lines.append(f"  {pool['symbol']}: {pool['risk_adj_apy']:.1f}%")
        
        lines.append("")
    
    # Regime with LP policy details (Russian)
    if opportunities_data:
        regime = opportunities_data.get("regime", "UNKNOWN")
        regime_penalty = opportunities_data.get("regime_penalty", 0)
        lp_recommendation = opportunities_data.get("lp_recommendation", "")
        
        lines.append(f"Ğ ĞµĞ¶Ğ¸Ğ¼: {regime}")
        if regime_penalty:
            # IL Penalty - ÑÑ‚Ğ¾ ÑˆÑ‚Ñ€Ğ°Ñ„ Ğ·Ğ° Ñ€Ğ¸ÑĞº Impermanent Loss Ğ¿Ñ€Ğ¸ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¼ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ Ñ€Ñ‹Ğ½ĞºĞ°
            lines.append(f"  Ğ¨Ñ‚Ñ€Ğ°Ñ„ IL: {regime_penalty:.0%} (ĞºĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ñ APY Ğ·Ğ° Ñ€Ğ¸ÑĞº Ğ½ĞµĞ¿Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ)")
        if lp_recommendation:
            lines.append(f"  {lp_recommendation}")
        lines.append("")
    
    # AI Summary
    if ai_summary:
        lines.append("AI:")
        lines.append(ai_summary)
    else:
        lines.append("AI: (Ğ½ĞµÑ‚ ĞºĞ»ÑÑ‡Ğ° OpenAI)")
    
    return "\n".join(lines)


def send_telegram(message: str) -> bool:
    """Send message to Telegram"""
    bot_token = os.getenv("TELEGRAM_BOT_TOKEN")
    chat_id = os.getenv("TELEGRAM_CHAT_ID")
    
    if not bot_token or not chat_id:
        logger.warning("Telegram credentials not set")
        return False
    
    try:
        url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
        response = requests.post(url, data={"chat_id": chat_id, "text": message}, timeout=10)
        
        if response.status_code == 200:
            logger.info("Telegram sent")
            return True
        else:
            logger.error(f"Telegram error: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"Telegram exception: {e}")
        return False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """Main entry point"""
    logger.info("=" * 60)
    logger.info("LP INTELLIGENCE SYSTEM v2.0.0")
    logger.info("=" * 60)
    
    # Load history
    history = load_history()
    logger.info(f"Loaded {len(history)} historical snapshots")
    
    # Stage 1: Monitor
    logger.info("\n--- STAGE 1: MONITOR ---")
    monitor_data = run_monitor()
    
    if not monitor_data:
        logger.error("Monitor failed - cannot continue")
        return 1
    
    logger.info(f"TVL: ${monitor_data['tvl']:,.0f}")
    logger.info(f"Positions: {monitor_data['count']}")
    
    # Save snapshot to history
    by_wallet_tvl = {k: v.get("balance_usd", 0) for k, v in monitor_data.get("by_wallet", {}).items()}
    by_wallet_fees = {k: v.get("fees_usd", 0) for k, v in monitor_data.get("by_wallet", {}).items()}
    add_snapshot(
        tvl=monitor_data["tvl"],
        fees=monitor_data["fees"],
        positions_count=monitor_data["count"],
        in_range=monitor_data["in_range"],
        by_wallet=by_wallet_tvl,
        by_wallet_fees=by_wallet_fees,
    )
    
    # Reload history after adding snapshot
    history = load_history()
    
    # Calculate portfolio APY (uses cumulative fees from history)
    portfolio_apy = calculate_portfolio_apy(history, monitor_data["tvl"])
    if portfolio_apy:
        logger.info(f"Portfolio APY: {portfolio_apy:.1f}%")
    
    # Stage 2: Opportunities
    logger.info("\n--- STAGE 2: OPPORTUNITIES ---")
    opportunities_data = run_opportunities()
    
    if opportunities_data:
        logger.info(f"Regime: {opportunities_data.get('regime')}")
        logger.info(f"Top pools: {len(opportunities_data.get('top_pools', []))}")
        # Add portfolio APY to opportunities data for comparison
        opportunities_data["portfolio_apy"] = portfolio_apy
    else:
        logger.warning("Opportunities scan failed")
    
    # Stage 3: Advisor
    logger.info("\n--- STAGE 3: ADVISOR ---")
    ai_summary = None
    
    openai_key = os.getenv("OPENAI_API_KEY")
    if not openai_key:
        logger.warning("OPENAI_API_KEY not set - AI summary disabled")
    elif monitor_data:
        ai_summary = run_advisor(monitor_data, opportunities_data, history)
        if ai_summary:
            logger.info(f"AI summary: {ai_summary[:100]}...")
        else:
            logger.warning("AI summary failed")
    
    # Generate unified report
    logger.info("\n--- GENERATING REPORT ---")
    report = format_unified_report(monitor_data, opportunities_data, ai_summary, history)
    
    print("\n" + "=" * 60)
    print(report)
    print("=" * 60)
    
    # Send to Telegram
    send_telegram(report)
    
    logger.info("\nDone!")
    return 0


if __name__ == "__main__":
    sys.exit(main())
